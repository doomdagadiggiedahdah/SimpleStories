{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create jsonl file with requests for batch completion\n",
    "\n",
    "import json\n",
    "import tiktoken\n",
    "import os\n",
    "from generate_stories import create_simple_story_prompt, iterate_params\n",
    "\n",
    "MODEL_PARAMETERS = {\"top_p\": 0.07}\n",
    "\n",
    "def get_batch_dataset(num_completions, model):\n",
    "    lines = []\n",
    "    total_tokens = 0\n",
    "    enc = tiktoken.encoding_for_model(model)\n",
    "    params_iterator = iterate_params()\n",
    "\n",
    "    for i in range(num_completions):\n",
    "        params = next(params_iterator)\n",
    "        prompt, num_stories_in_completion = create_simple_story_prompt(params.copy())\n",
    "        message_tokens = len(enc.encode(prompt))\n",
    "        total_tokens += message_tokens\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "        lines.append(json.dumps(\n",
    "            {\"custom_id\": str(i)+json.dumps(params | {\"expected_num_stories_in_completion\": num_stories_in_completion}),\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\"model\": model, \"messages\": messages, **MODEL_PARAMETERS}}\n",
    "            ))\n",
    "    \n",
    "    print(f\"Total input tokens: {total_tokens}\")\n",
    "\n",
    "    return lines\n",
    "\n",
    "def write_batch_completion_file(num_completions, model, filename):\n",
    "    lines = get_batch_dataset(num_completions, model)\n",
    "    with open(filename, \"w\") as fp:\n",
    "        fp.write(\"\\n\".join(lines))\n",
    "    \n",
    "if not os.path.exists(\"data\"):\n",
    "    os.makedirs(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Generation:   0%|          | 0/100000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total input tokens: 1667804\n",
      "Batch status: validating\n",
      "The input file is being validated. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n",
      "Batch status: in_progress\n",
      "The batch is currently being processed. Please wait...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Generation:   0%|          | 0/100000 [55:44<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 96\u001b[0m\n\u001b[0;32m     93\u001b[0m batch_id \u001b[38;5;241m=\u001b[39m batch_info\u001b[38;5;241m.\u001b[39mid\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# 4. Check the status and download the results\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcheck_batch_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     97\u001b[0m     total_completions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m NUM_COMPLETIONS_PER_REQUEST\n\u001b[0;32m     98\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(NUM_COMPLETIONS_PER_REQUEST)\n",
      "Cell \u001b[1;32mIn[6], line 47\u001b[0m, in \u001b[0;36mcheck_batch_status\u001b[1;34m(batch_id, batch_number, directory)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown status encountered.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 47\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 2. Execute Batch Jobs\n",
    "\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "        \n",
    "NUM_COMPLETIONS = 100_000\n",
    "NUM_COMPLETIONS_PER_REQUEST = 10_000 # Calculate this based on rate limits, to be checked at https://platform.openai.com/settings/organization/limits\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY_SIMPLESTORIES\"])\n",
    "\n",
    "def check_batch_status(batch_id, batch_number, directory):\n",
    "    while True:\n",
    "        batch_status = client.batches.retrieve(batch_id)\n",
    "\n",
    "        status = batch_status.status\n",
    "        print(f\"Batch status: {status}\")\n",
    "\n",
    "        if status == \"validating\":\n",
    "            print(\"The input file is being validated. Please wait...\")\n",
    "        elif status == \"failed\":\n",
    "            print(\"The input file has failed validation.\")\n",
    "            return False\n",
    "        elif status == \"in_progress\":\n",
    "            print(\"The batch is currently being processed. Please wait...\")\n",
    "        elif status == \"finalizing\":\n",
    "            print(\"The batch is completed and the results are being prepared.\")\n",
    "        elif status == \"completed\":\n",
    "            print(\"The batch is complete, downloading the results...\")\n",
    "            download_batch_results(batch_status.output_file_id, batch_number, directory)\n",
    "            return True\n",
    "        elif status == \"expired\":\n",
    "            print(\"The batch was not completed within the 24-hour time window.\")\n",
    "            return False\n",
    "        elif status == \"cancelling\":\n",
    "            print(\"The batch is being cancelled. Please wait...\")\n",
    "        elif status == \"cancelled\":\n",
    "            print(\"The batch was cancelled.\")\n",
    "            return False\n",
    "        else:\n",
    "            print(\"Unknown status encountered.\")\n",
    "\n",
    "        time.sleep(30)  # Wait for 30 seconds before checking the status again\n",
    "        \n",
    "def download_batch_results(output_file_id, batch_number, directory):\n",
    "    with open(os.path.join(directory, \"output_file_ids.txt\"), \"a\") as f:\n",
    "        f.write(output_file_id + \"\\n\")\n",
    "\n",
    "    file_response = client.files.content(output_file_id)\n",
    "    \n",
    "    filename = f\"{directory}/batch_data_{batch_number}.jsonl\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(file_response.text)\n",
    "total_completions = 0\n",
    "batch_number = 0\n",
    "consecutive_failures = 0\n",
    "\n",
    "directory = os.path.join(\"data\", f\"batches_{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\")\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "os.makedirs(os.path.join(directory, \"prompts\"), exist_ok=True)\n",
    "\n",
    "with tqdm(total=NUM_COMPLETIONS, desc=\"Batch Generation\") as pbar:\n",
    "    while total_completions < NUM_COMPLETIONS and consecutive_failures < MAX_RETRIES:\n",
    "        try:\n",
    "            # 1. Write the batch completion file\n",
    "            batch_number += 1\n",
    "            filename = os.path.join(directory, \"prompts\", f\"{batch_number}.jsonl\")\n",
    "            write_batch_completion_file(NUM_COMPLETIONS_PER_REQUEST, MODEL, filename)\n",
    "\n",
    "            # 2. Upload the batch file\n",
    "            batch_input_file = client.files.create(\n",
    "                file=open(filename, \"rb\"),\n",
    "                purpose=\"batch\"\n",
    "            )\n",
    "            batch_input_file_id = batch_input_file.id\n",
    "            with open(os.path.join(directory, \"input_file_ids.txt\"), \"a\") as f:\n",
    "                f.write(batch_input_file_id + \"\\n\")\n",
    "\n",
    "            # 3. Create the batch job\n",
    "            batch_info = client.batches.create(\n",
    "                input_file_id=batch_input_file_id,\n",
    "                endpoint=\"/v1/chat/completions\",\n",
    "                completion_window=\"24h\",\n",
    "                metadata={\n",
    "                    \"description\": f\"Simple Stories Story Generation - batch {batch_number}, n={NUM_COMPLETIONS_PER_REQUEST}\"\n",
    "                }\n",
    "            )\n",
    "\n",
    "            batch_id = batch_info.id\n",
    "            with open(os.path.join(directory, \"batch_job_ids.txt\"), \"a\") as f:\n",
    "                f.write(batch_id + \"\\n\")\n",
    "\n",
    "            # 4. Check the status and download the results\n",
    "            if check_batch_status(batch_id, batch_number, directory):\n",
    "                total_completions += NUM_COMPLETIONS_PER_REQUEST\n",
    "                pbar.update(NUM_COMPLETIONS_PER_REQUEST)\n",
    "                consecutive_failures = 0\n",
    "            else:\n",
    "                consecutive_failures += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            consecutive_failures += 1\n",
    "\n",
    "    if consecutive_failures >= MAX_RETRIES:\n",
    "        print(f\"Stopping due to {MAX_RETRIES} consecutive failures.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Format batch output\n",
    "import re\n",
    "import json\n",
    "\n",
    "from generate_stories import process_completion\n",
    "\n",
    "def format_jsonl(input_file, output_file):\n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "        for line in infile:\n",
    "            data = json.loads(line)\n",
    "            \n",
    "            custom_id = data['custom_id']\n",
    "            match = re.search(r'{.*}', custom_id)\n",
    "            if match:\n",
    "                params = json.loads(match.group(0))\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            completion = data['response']['body']['choices'][0]['message']['content']\n",
    "            gen_model = data['response']['body']['model']\n",
    "            \n",
    "            json_struct = process_completion(gen_model, completion, params, expected_num_stories=params.get(\"expected_num_in_stories\", None))\n",
    "            lines = [json.dumps(item) for item in json_struct if 'story' in item]\n",
    "            outfile.write(\"\\n\".join(lines) + \"\\n\")\n",
    "\n",
    "input_file = 'data/gpt-4o-mini_200_completions.jsonl'\n",
    "output_file = input_file.replace('.jsonl', '_processed.jsonl')\n",
    "\n",
    "format_jsonl(input_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Proceed to either analyse_dataset.ipynb or embeddings.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
